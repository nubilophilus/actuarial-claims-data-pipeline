# Claims-to-Insights: An Actuarial Data Engineering Project  
### by Ras Ade

---

## Overview

This project explores how I built a cloud-based data pipeline that helps turn raw insurance claims and policy data into something more useful‚Äîclear insights for teams like actuarial, underwriting, and business leadership.

It brings together data engineering and actuarial logic to reduce manual work, improve accuracy, and support faster, better decisions.

---

## Why It‚Äôs Useful

In most insurance environments, it takes a lot of time to clean and connect data before it‚Äôs ready for modeling or reporting. This project helps fix that by:

- Automating the cleanup and prep work  
- Connecting claims and policy data with actuarial models  
- Creating reusable features that plug into forecasting tools  
- Laying a solid foundation for audit-ready, repeatable insights  

The idea is to make things easier for teams without sacrificing accuracy or compliance.

---

## Tools I Used

| Area         | Tools & Services                  |
|--------------|-----------------------------------|
| Cloud        | AWS Glue, S3, Lambda              |
| Programming  | Python, SQL, Pandas, PySpark      |
| Modeling     | GLM and XGBoost via SageMaker     |
| Monitoring   | Great Expectations, AWS SNS       |
| Storage      | Redshift and S3                   |

---

## Real-World Scenarios

- Helping actuaries prep reserve data faster and more consistently  
- Giving underwriters access to loss trends without long lead times  
- Providing leaders with easier access to ratios and projections  

---

## Results I Focused On

- Reduced manual data prep time by around **40%**  
- Improved forecast accuracy by about **12%**  
- Created a system that passed audit with **zero revision requests**  
- Set it up so it can be reused across other product lines  

---

## What‚Äôs in This Repo

| Folder/File             | What It Contains                        |
|-------------------------|------------------------------------------|
| `etl_pipeline/`         | Scripts that clean and transform data    |
| `features/`             | Feature logic and how it‚Äôs calculated    |
| `models/`               | Example modeling steps and configs       |
| `notebooks/`            | Walkthroughs in Jupyter format           |
| `README.md`             | This document                            |

---

## For Wes Hutchinson and Kerrie Porter

Thanks for taking the time to explore this. My goal here was to show how I think about data in an actuarial context‚Äîcombining the technical side with the business need.

If you're looking for someone who can translate between actuarial logic, cloud data tools, and real-world insurance problems, I‚Äôd love to talk more.

üìß Email: [YourEmail@example.com]  
üåê LinkedIn: [linkedin.com/in/rasade]  
üìç Based in Henderson, NV ‚Äì open to remote or hybrid

---
